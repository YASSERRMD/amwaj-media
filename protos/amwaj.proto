syntax = "proto3";

package amwaj.media;

service AmwajMediaServer {
    rpc HandleMediaStream(stream MediaEvent) returns (stream OrchestrationCommand);
}

message MediaEvent {
    string session_id = 1;
    int64 timestamp_ms = 2;
    
    oneof event {
        AudioFrame audio_frame = 3;
        TurnStarted turn_started = 4;
        TurnEnded turn_ended = 5;
        PartialTranscript partial_transcript = 6;
        LatencyMetrics metrics = 7;
        SessionEnded session_ended = 8;
    }
}

message AudioFrame {
    bytes pcm_data = 1;
    uint32 sample_rate = 2;
    uint32 channels = 3;
    int64 frame_timestamp_ms = 4;
}

message TurnStarted {
    float vad_probability = 1;
    float volume_db = 2;
    int64 timestamp_ms = 3;
}

message TurnEnded {
    string transcript_preview = 1;
    int64 timestamp_ms = 2;
    uint32 duration_ms = 3;
}

message PartialTranscript {
    string text = 1;
    float confidence = 2;
    int64 timestamp_ms = 3;
}

message LatencyMetrics {
    string component = 1;
    uint32 processing_ms = 2;
    int64 timestamp_ms = 3;
    map<string, string> tags = 4;
}

message SessionEnded {
    string session_id = 1;
    int64 duration_ms = 2;
    uint32 total_frames = 3;
}

message OrchestrationCommand {
    string session_id = 1;
    int64 timestamp_ms = 2;
    
    oneof command {
        PlayAudio play_audio = 3;
        StopAudio stop_audio = 4;
        ClearContext clear_context = 5;
        AdjustVAD adjust_vad = 6;
    }
}

message PlayAudio {
    bytes audio_data = 1;
    string audio_format = 2;
    int64 sequence_number = 3;
}

message StopAudio {
    string reason = 1;
}

message ClearContext {
    string context_type = 1;
}

message AdjustVAD {
    float sensitivity = 1;
    uint32 threshold_ms = 2;
}
